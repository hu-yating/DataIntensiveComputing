{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cec307-c206-471c-9bb0-c0a85baa6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.datastax.spark:spark-cassandra-connector_2.11:2.3.0 --conf spark.cassandra.connection.host=127.0.0.1 --jars /home/osboxes/spark-streaming-kafka-0-8-assembly_2.11-2.4.3.jar pyspark-shell --master local[2]'\n",
    "\n",
    "# initialize spark\n",
    "import pyspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import RDD\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import json\n",
    "\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import IntegerType, LongType, DecimalType,StructType, StructField, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea18d0c-d47e-4917-acca-e579f7d9adbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fa8d4e85a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install cassandra-driver\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['localhost'])\n",
    "session = cluster.connect()\n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS finalproject WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor' : 1};\")\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS finalProject.news (title text PRIMARY KEY, date timestamp, sentiment double, type text)\")\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS finalProject.bitcoin (date timestamp PRIMARY KEY, price double, type text)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24eb7979-cd71-4476-8957-84e4576778b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.execute(\"DROP TABLE finalProject.news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb70f721-2643-4f83-8b85-a0adb199c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"PythonSparkStreamingKafka\")\n",
    "ssc = StreamingContext(sc,2)\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [\"news\", \"bitcoin\"], {\"metadata.broker.list\":\"localhost:9092\"})\n",
    "rdd = kafkaStream.map(lambda v: json.loads(v[1]))\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb235758-56d8-4d0b-9258-b35cebd10835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------INCOMING NEW DATA-----------------\n",
      "+--------------------+----------+---------+----+\n",
      "|               title|      date|sentiment|type|\n",
      "+--------------------+----------+---------+----+\n",
      "|GOP congressman: ...|2021-10-21|  -0.9001|news|\n",
      "+--------------------+----------+---------+----+\n",
      "\n",
      "+----------+----------+-------+\n",
      "|      date|     price|   type|\n",
      "+----------+----------+-------+\n",
      "|2021-10-21|62201.9633|bitcoin|\n",
      "+----------+----------+-------+\n",
      "\n",
      "------------Save new data to Cassandra------------\n",
      "Saved news\n",
      "Saved bitcoin\n",
      "-----------Read new data from Cassandra-----------\n",
      "Read news\n",
      "Read bitcoin\n",
      "----------------Evaluating Models-----------------\n",
      "Root Mean Squared Error (RMSE) on Linear Regression = 2013.21\n",
      "R Squared (R2) on Linear Regression = -0.0423031\n",
      "Root Mean Squared Error (RMSE) on Decision Tree Regression = 2502.02\n",
      "Root Mean Squared Error (RMSE) on Gradient-Boosted Trees Regression = 2440.01\n",
      "--------Output prediction of incoming news--------\n",
      "Coefficients: [-545.4629003729633]\n",
      "Intercept: 62785.9624516099\n",
      "-----------Linear Regression prediciton-----------\n",
      "+----------+----------------+\n",
      "|      date|      prediction|\n",
      "+----------+----------------+\n",
      "|2021-10-21|63276.9336082356|\n",
      "+----------+----------------+\n",
      "\n",
      "-------Decision Tree Regression prediciton--------\n",
      "+----------+-----------+\n",
      "|      date| prediction|\n",
      "+----------+-----------+\n",
      "|2021-10-21|62432.38334|\n",
      "+----------+-----------+\n",
      "\n",
      "---Gradient-Boosted Trees Regression prediciton---\n",
      "+----------+------------------+\n",
      "|      date|        prediction|\n",
      "+----------+------------------+\n",
      "|2021-10-21|62924.808321238495|\n",
      "+----------+------------------+\n",
      "\n",
      "-----------------------END------------------------\n"
     ]
    }
   ],
   "source": [
    "# Reference https://stackoverflow.com/questions/50274793/spark-streaming-dstream-messages-in-json-format-to-dataframe\n",
    "debug_flag = False\n",
    "\n",
    "def readMyStream(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        df = spark.read.json(rdd)\n",
    "        news = df.select(\"title\",'date','sentiment',\"type\").where(col(\"type\")==\"news\")\n",
    "        bitcoin = df.select('date','price',\"type\").where(col(\"type\")==\"bitcoin\")\n",
    "        \n",
    "        print(\"INCOMING NEW DATA\".center(50, '-'))\n",
    "        news.show()\n",
    "        bitcoin.show()\n",
    "        \n",
    "        print(\"Save new data to Cassandra\".center(50, '-'))\n",
    "        # save new data to Cassandra\n",
    "        news.write\\\n",
    "            .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "            .mode('append')\\\n",
    "            .options(table=\"news\", keyspace=\"finalproject\")\\\n",
    "            .save()\n",
    "        print(\"Saved news\")\n",
    "\n",
    "        bitcoin.write\\\n",
    "            .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "            .mode('append')\\\n",
    "            .options(table=\"bitcoin\", keyspace=\"finalproject\")\\\n",
    "            .save()\n",
    "        print(\"Saved bitcoin\")\n",
    "        \n",
    "        print(\"Read new data from Cassandra\".center(50, '-'))\n",
    "        # read from Cassandra\n",
    "        spark_sent = sqlContext.read\\\n",
    "            .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "            .options(table=\"news\", keyspace=\"finalproject\")\\\n",
    "            .load().select([\"date\",\"sentiment\"])\n",
    "        if debug_flag:\n",
    "            spark_sent.printSchema()\n",
    "        print(\"Read news\")\n",
    "        \n",
    "        spark_bitcoin = sqlContext.read\\\n",
    "            .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "            .options(table=\"bitcoin\", keyspace=\"finalproject\")\\\n",
    "            .load().select([\"date\",\"price\"]).withColumnRenamed(\"price\", \"bitcoin\")\n",
    "        if debug_flag:\n",
    "            spark_bitcoin.printSchema()\n",
    "        print(\"Read bitcoin\")\n",
    "        \n",
    "        # Join both on date column\n",
    "        sparkDF = spark_sent.join(spark_bitcoin,spark_sent.date ==  spark_bitcoin.date,\"inner\")\n",
    "        \n",
    "        # Define features\n",
    "        assembler = VectorAssembler().setInputCols(['sentiment']).setOutputCol('features')\n",
    "        DF = assembler.transform(sparkDF)\n",
    "        \n",
    "        # Split data into train/test\n",
    "        splits = DF.randomSplit([0.7, 0.3])\n",
    "        train_df = splits[0]\n",
    "        test_df = splits[1]\n",
    "        \n",
    "        print(\"Evaluating Models\".center(50, '-'))\n",
    "        # Linear Regression\n",
    "        lr = LinearRegression(featuresCol = 'features', labelCol='bitcoin', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "        lr_model = lr.fit(train_df)\n",
    "        # Apply regression model on test data\n",
    "        lr_predictions = lr_model.transform(test_df)\n",
    "        test_result = lr_model.evaluate(test_df)\n",
    "        lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                                         labelCol=\"bitcoin\",metricName=\"r2\") \n",
    "        print(\"Root Mean Squared Error (RMSE) on Linear Regression = %g\" % test_result.rootMeanSquaredError)\n",
    "        print(\"R Squared (R2) on Linear Regression = %g\" % lr_evaluator.evaluate(lr_predictions))\n",
    "        \n",
    "        # Decision Tree Regression\n",
    "        dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'bitcoin')\n",
    "        dt_model = dt.fit(train_df)\n",
    "        dt_predictions = dt_model.transform(test_df)\n",
    "        dt_evaluator = RegressionEvaluator(\n",
    "            labelCol=\"bitcoin\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "        rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "        print(\"Root Mean Squared Error (RMSE) on Decision Tree Regression = %g\" % rmse) \n",
    "        \n",
    "        # Gradient-Boosted Trees Regression\n",
    "        gbt = GBTRegressor(featuresCol = 'features', labelCol = 'bitcoin', maxIter=10)\n",
    "        gbt_model = gbt.fit(train_df)\n",
    "        gbt_predictions = gbt_model.transform(test_df)\n",
    "        gbt_evaluator = RegressionEvaluator(labelCol=\"bitcoin\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "        rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "        print(\"Root Mean Squared Error (RMSE) on Gradient-Boosted Trees Regression = %g\" % rmse)\n",
    "        \n",
    "        print(\"Output prediction of incoming news\".center(50, '-'))\n",
    "        ## output prediction of the day\n",
    "        if debug_flag:\n",
    "            news.printSchema()\n",
    "            sparkDF.printSchema()\n",
    "        \n",
    "        assembler = VectorAssembler().setInputCols(['sentiment']).setOutputCol('features')\n",
    "        train_df = assembler.transform(sparkDF)\n",
    "        incoming_news = assembler.transform(news.select([\"date\", \"sentiment\"]).withColumn(\"sentiment\",col(\"sentiment\").cast(\"double\")))\n",
    "        \n",
    "        if debug_flag:\n",
    "            incoming_news.show()\n",
    "            incoming_news.printSchema()\n",
    "\n",
    "        lr = LinearRegression(featuresCol = 'features', labelCol='bitcoin', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "        lr_model = lr.fit(train_df)\n",
    "        print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "        print(\"Intercept: \" + str(lr_model.intercept))\n",
    "        \n",
    "        lr_predictions = lr_model.transform(incoming_news)\n",
    "        print(\"Linear Regression prediciton\".center(50, '-'))\n",
    "        lr_predictions.select([\"date\", \"prediction\"]).show(5)\n",
    "\n",
    "        dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'bitcoin')\n",
    "        dt_model = dt.fit(train_df)\n",
    "        dt_predictions = dt_model.transform(incoming_news)\n",
    "        print(\"Decision Tree Regression prediciton\".center(50, '-'))\n",
    "        dt_predictions.select([\"date\", \"prediction\"]).show(5)\n",
    "        \n",
    "        gbt = GBTRegressor(featuresCol = 'features', labelCol = 'bitcoin', maxIter=10)\n",
    "        gbt_model = gbt.fit(train_df)\n",
    "        gbt_predictions = gbt_model.transform(incoming_news)\n",
    "        print(\"Gradient-Boosted Trees Regression prediciton\".center(50, '-'))\n",
    "        gbt_predictions.select([\"date\", \"prediction\"]).show(5)\n",
    "\n",
    "        print(\"END\".center(50, '-'))\n",
    "rdd.foreachRDD(lambda rdd: readMyStream(rdd))\n",
    "\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3112360-d720-405e-9e8c-2011c09a7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dic",
   "language": "python",
   "name": "dic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
